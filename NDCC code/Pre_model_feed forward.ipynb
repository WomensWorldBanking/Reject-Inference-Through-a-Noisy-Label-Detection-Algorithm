{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be812d55",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438e7cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch [1/50], Validation Loss: 0.5175, Accuracy: 84.55%\n",
      "Epoch [2/50], Validation Loss: 0.3846, Accuracy: 84.55%\n",
      "Epoch [3/50], Validation Loss: 0.3537, Accuracy: 84.55%\n",
      "Epoch [4/50], Validation Loss: 0.3361, Accuracy: 84.55%\n",
      "Epoch [5/50], Validation Loss: 0.3239, Accuracy: 84.55%\n",
      "Epoch [6/50], Validation Loss: 0.3178, Accuracy: 85.45%\n",
      "Epoch [7/50], Validation Loss: 0.3129, Accuracy: 87.27%\n",
      "Epoch [8/50], Validation Loss: 0.3100, Accuracy: 87.73%\n",
      "Epoch [9/50], Validation Loss: 0.3059, Accuracy: 88.18%\n",
      "Epoch [10/50], Validation Loss: 0.3131, Accuracy: 88.18%\n",
      "Epoch [11/50], Validation Loss: 0.3157, Accuracy: 89.55%\n",
      "Epoch [12/50], Validation Loss: 0.3167, Accuracy: 90.00%\n",
      "Epoch [13/50], Validation Loss: 0.3214, Accuracy: 90.00%\n",
      "Epoch [14/50], Validation Loss: 0.3184, Accuracy: 90.45%\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.47      0.60        34\n",
      "           1       0.91      0.98      0.95       186\n",
      "\n",
      "    accuracy                           0.90       220\n",
      "   macro avg       0.88      0.73      0.77       220\n",
      "weighted avg       0.90      0.90      0.89       220\n",
      "\n",
      "\n",
      "Fold 2\n",
      "Epoch [1/50], Validation Loss: 0.5144, Accuracy: 80.00%\n",
      "Epoch [2/50], Validation Loss: 0.4369, Accuracy: 80.00%\n",
      "Epoch [3/50], Validation Loss: 0.3927, Accuracy: 80.00%\n",
      "Epoch [4/50], Validation Loss: 0.3714, Accuracy: 80.00%\n",
      "Epoch [5/50], Validation Loss: 0.3503, Accuracy: 84.09%\n",
      "Epoch [6/50], Validation Loss: 0.3437, Accuracy: 84.09%\n",
      "Epoch [7/50], Validation Loss: 0.3295, Accuracy: 84.09%\n",
      "Epoch [8/50], Validation Loss: 0.3218, Accuracy: 84.09%\n",
      "Epoch [9/50], Validation Loss: 0.3188, Accuracy: 83.18%\n",
      "Epoch [10/50], Validation Loss: 0.3138, Accuracy: 85.45%\n",
      "Epoch [11/50], Validation Loss: 0.3163, Accuracy: 85.45%\n",
      "Epoch [12/50], Validation Loss: 0.3203, Accuracy: 85.45%\n",
      "Epoch [13/50], Validation Loss: 0.3198, Accuracy: 88.18%\n",
      "Epoch [14/50], Validation Loss: 0.3207, Accuracy: 88.64%\n",
      "Epoch [15/50], Validation Loss: 0.3127, Accuracy: 88.18%\n",
      "Epoch [16/50], Validation Loss: 0.3244, Accuracy: 89.09%\n",
      "Epoch [17/50], Validation Loss: 0.3168, Accuracy: 90.91%\n",
      "Epoch [18/50], Validation Loss: 0.3326, Accuracy: 90.45%\n",
      "Epoch [19/50], Validation Loss: 0.3374, Accuracy: 90.00%\n",
      "Epoch [20/50], Validation Loss: 0.3424, Accuracy: 90.00%\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        44\n",
      "           1       0.91      0.97      0.94       176\n",
      "\n",
      "    accuracy                           0.90       220\n",
      "   macro avg       0.87      0.80      0.83       220\n",
      "weighted avg       0.90      0.90      0.89       220\n",
      "\n",
      "\n",
      "Fold 3\n",
      "Epoch [1/50], Validation Loss: 0.4665, Accuracy: 82.27%\n",
      "Epoch [2/50], Validation Loss: 0.4144, Accuracy: 82.27%\n",
      "Epoch [3/50], Validation Loss: 0.3906, Accuracy: 81.82%\n",
      "Epoch [4/50], Validation Loss: 0.3852, Accuracy: 80.91%\n",
      "Epoch [5/50], Validation Loss: 0.3874, Accuracy: 80.00%\n",
      "Epoch [6/50], Validation Loss: 0.3900, Accuracy: 80.00%\n",
      "Epoch [7/50], Validation Loss: 0.3958, Accuracy: 82.73%\n",
      "Epoch [8/50], Validation Loss: 0.3875, Accuracy: 83.64%\n",
      "Epoch [9/50], Validation Loss: 0.3959, Accuracy: 84.09%\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.41      0.48        39\n",
      "           1       0.88      0.93      0.91       181\n",
      "\n",
      "    accuracy                           0.84       220\n",
      "   macro avg       0.73      0.67      0.69       220\n",
      "weighted avg       0.83      0.84      0.83       220\n",
      "\n",
      "\n",
      "Fold 4\n",
      "Epoch [1/50], Validation Loss: 0.4907, Accuracy: 82.73%\n",
      "Epoch [2/50], Validation Loss: 0.4456, Accuracy: 82.73%\n",
      "Epoch [3/50], Validation Loss: 0.4295, Accuracy: 82.73%\n",
      "Epoch [4/50], Validation Loss: 0.4206, Accuracy: 82.73%\n",
      "Epoch [5/50], Validation Loss: 0.4163, Accuracy: 80.45%\n",
      "Epoch [6/50], Validation Loss: 0.4039, Accuracy: 81.36%\n",
      "Epoch [7/50], Validation Loss: 0.4062, Accuracy: 83.18%\n",
      "Epoch [8/50], Validation Loss: 0.3933, Accuracy: 83.18%\n",
      "Epoch [9/50], Validation Loss: 0.3918, Accuracy: 83.18%\n",
      "Epoch [10/50], Validation Loss: 0.3877, Accuracy: 84.09%\n",
      "Epoch [11/50], Validation Loss: 0.3917, Accuracy: 83.18%\n",
      "Epoch [12/50], Validation Loss: 0.3934, Accuracy: 84.55%\n",
      "Epoch [13/50], Validation Loss: 0.3914, Accuracy: 85.91%\n",
      "Epoch [14/50], Validation Loss: 0.3942, Accuracy: 85.91%\n",
      "Epoch [15/50], Validation Loss: 0.4049, Accuracy: 84.55%\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50        38\n",
      "           1       0.89      0.93      0.91       182\n",
      "\n",
      "    accuracy                           0.85       220\n",
      "   macro avg       0.73      0.69      0.70       220\n",
      "weighted avg       0.83      0.85      0.84       220\n",
      "\n",
      "\n",
      "Fold 5\n",
      "Epoch [1/50], Validation Loss: 0.4562, Accuracy: 88.18%\n",
      "Epoch [2/50], Validation Loss: 0.3381, Accuracy: 88.18%\n",
      "Epoch [3/50], Validation Loss: 0.3054, Accuracy: 88.18%\n",
      "Epoch [4/50], Validation Loss: 0.2903, Accuracy: 88.64%\n",
      "Epoch [5/50], Validation Loss: 0.2822, Accuracy: 89.09%\n",
      "Epoch [6/50], Validation Loss: 0.2769, Accuracy: 87.73%\n",
      "Epoch [7/50], Validation Loss: 0.2766, Accuracy: 88.18%\n",
      "Epoch [8/50], Validation Loss: 0.2791, Accuracy: 87.27%\n",
      "Epoch [9/50], Validation Loss: 0.2852, Accuracy: 86.82%\n",
      "Epoch [10/50], Validation Loss: 0.2886, Accuracy: 87.73%\n",
      "Epoch [11/50], Validation Loss: 0.2918, Accuracy: 87.27%\n",
      "Early stopping triggered.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.23      0.30        26\n",
      "           1       0.90      0.96      0.93       194\n",
      "\n",
      "    accuracy                           0.87       220\n",
      "   macro avg       0.67      0.59      0.61       220\n",
      "weighted avg       0.85      0.87      0.86       220\n",
      "\n",
      "\n",
      "Best Model Accuracy: 90.45%\n"
     ]
    }
   ],
   "source": [
    "# Loads the clean version of Dpre and trains the pretrained model of NDCC (g)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=2, min_delta=0.0005):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def evaluate_model(val_loader, model):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "train_dataset = torch.load('Dpre_clean.pth')\n",
    "features_tensor, labels_tensor = train_dataset.tensors  \n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_model_wts = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(features_tensor), 1):\n",
    "    print(f'\\nFold {fold}')\n",
    "    X_train, X_val = features_tensor[train_idx], features_tensor[val_idx]\n",
    "    y_train, y_val = labels_tensor[train_idx], labels_tensor[val_idx]\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    model = Net(70, 64, 2) \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Added weight decay\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(50): \n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/50], Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_wts = model.state_dict()\n",
    "\n",
    "    evaluate_model(val_loader, model)\n",
    "\n",
    "if best_model_wts:\n",
    "    torch.save(best_model_wts, 'FeedForward_Enhanced.pth')\n",
    "    print(f'\\nBest Model Accuracy: {best_accuracy:.2f}%')\n",
    "else:\n",
    "    print(\"No model was saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e17b109-2a85-49e8-8a62-22a28164ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model g on D_validation_clean: 87.53%\n"
     ]
    }
   ],
   "source": [
    "# calculates the accuracy of the pretrained model on validation dataset\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "input_size = 70 \n",
    "model = Net(input_size=input_size, hidden_size=64, num_classes=2)\n",
    "\n",
    "dataset_path = 'D_validation_clean.pth'\n",
    "train_dataset = torch.load(dataset_path)\n",
    "features_tensor, labels_tensor = train_dataset.tensors\n",
    "\n",
    "val_dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "model = Net(input_size=70, hidden_size=64)\n",
    "model_path = 'FeedForward_Enhanced.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "def evaluate_model(val_loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate_model(val_loader, model)\n",
    "print(f'Accuracy of the model g on D_validation_clean: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17285f9e-5298-4c09-aee9-ebe0a8a17689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch20_p39_gpu_v2]",
   "language": "python",
   "name": "conda-env-pytorch20_p39_gpu_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
